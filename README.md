# ElRoi Vision - Object Detection API

API de detec√ß√£o de objetos usando YOLOv8 e FastAPI. Esta API permite detectar objetos em imagens e retornar os resultados em formato JSON ou como imagem anotada com bounding boxes.

## üìã √çndice

- [Funcionalidades](#funcionalidades)
- [Endpoints](#endpoints)
- [Instala√ß√£o e Configura√ß√£o](#instala√ß√£o-e-configura√ß√£o)
- [Vari√°veis de Ambiente](#vari√°veis-de-ambiente)
- [Uso da API](#uso-da-api)
- [Deploy no EasyPanel](#deploy-no-easypanel)
- [Documenta√ß√£o Swagger](#documenta√ß√£o-swagger)
- [Testes](#testes)

## üöÄ Funcionalidades

- **Detec√ß√£o de Objetos**: Detecta objetos em imagens usando modelos YOLOv8 pr√©-treinados
- **Resposta em JSON**: Retorna objetos detectados com nome e confian√ßa
- **Resposta em Imagem**: Retorna imagem anotada com bounding boxes e labels
- **OCR**: Extra√ß√£o de texto de imagens usando EasyOCR ou Tesseract
- **An√°lise de Cores**: Identifica cores dominantes e impacto emocional
- **Gera√ß√£o de Descri√ß√£o**: Gera descri√ß√µes autom√°ticas de imagens usando BLIP
- **An√°lise Emocional**: Detecta emo√ß√µes em faces usando DeepFace
- **An√°lise de Aten√ß√£o**: Mapa de sali√™ncia e pontos de foco visual
- **Detec√ß√£o de CTAs**: Identifica elementos Call-to-Action
- **Relat√≥rio Neuromarketing**: An√°lise completa combinando todas as funcionalidades
- **Healthcheck**: Endpoint para verificar status do servi√ßo
- **Documenta√ß√£o Swagger**: Documenta√ß√£o interativa autom√°tica

## üì° Endpoints

### 1. `GET /healthcheck`

Verifica o status do servi√ßo.

**Resposta:**
```json
{
  "healthcheck": "Everything OK!"
}
```

**Exemplo:**
```bash
curl http://localhost:8001/healthcheck
```

### 2. `POST /img_object_detection_to_json`

Detecta objetos em uma imagem e retorna os resultados em formato JSON.

**Par√¢metros:**
- `file` (multipart/form-data): Arquivo de imagem (JPEG, PNG, WEBP, etc.)

**Resposta:**
```json
{
  "detect_objects": [
    {
      "name": "person",
      "confidence": 0.95
    },
    {
      "name": "car",
      "confidence": 0.87
    }
  ],
  "detect_objects_names": "person, car"
}
```

**Exemplo com curl:**
```bash
curl -X POST "http://localhost:8001/img_object_detection_to_json" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@test_image.jpg"
```

**Exemplo com Python:**
```python
import requests

with open('test_image.jpg', 'rb') as f:
    response = requests.post(
        'http://localhost:8001/img_object_detection_to_json',
        files={'file': f}
    )

data = response.json()     
print(data)
```

### 3. `POST /img_object_detection_to_img`

Detecta objetos em uma imagem e retorna a imagem anotada com bounding boxes.

**Par√¢metros:**
- `file` (multipart/form-data): Arquivo de imagem (JPEG, PNG, WEBP, etc.)

**Resposta:**
- Imagem JPEG com bounding boxes e labels desenhados

**Exemplo com curl:**
```bash
curl -X POST "http://localhost:8001/img_object_detection_to_img" \
     -H "accept: image/jpeg" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@test_image.jpg" \
     --output result.jpg
```

**Exemplo com Python:**
```python
import requests

with open('test_image.jpg', 'rb') as f:
    response = requests.post(
        'http://localhost:8001/img_object_detection_to_img',
        files={'file': f}
    )

with open('result.jpg', 'wb') as f:
    f.write(response.content)
```

### 4. `POST /img_text_extraction`

Extrai texto de uma imagem usando OCR (Optical Character Recognition).

**Par√¢metros:**
- `file` (multipart/form-data): Arquivo de imagem
- `method` (query, opcional): M√©todo de OCR - "easyocr" ou "tesseract" (padr√£o: "easyocr")

**Resposta:**
```json
{
  "full_text": "Frete Gr√°tis Compre Agora",
  "segments": [
    {
      "text": "Frete Gr√°tis",
      "confidence": 0.95,
      "bbox": {"xmin": 100, "ymin": 50, "xmax": 300, "ymax": 80}
    }
  ],
  "total_segments": 1,
  "method_used": "easyocr"
}
```

**Exemplo:**
```bash
curl -X POST "http://localhost:8001/img_text_extraction?method=easyocr" \
     -F "file=@test_image.jpg"
```

### 5. `POST /img_color_analysis`

Analisa cores dominantes e impacto emocional de uma imagem.

**Par√¢metros:**
- `file` (multipart/form-data): Arquivo de imagem
- `n_colors` (query, opcional): N√∫mero de cores dominantes (padr√£o: 5, m√°ximo: 10)

**Resposta:**
```json
{
  "dominant_colors": [
    {
      "rgb": [255, 100, 50],
      "hex": "#FF6432",
      "percentage": 35.5,
      "emotion_tag": "warm-energetic"
    }
  ],
  "average_contrast": 4.8,
  "emotion_palette": "warm-energetic",
  "color_count": 5
}
```

**Exemplo:**
```bash
curl -X POST "http://localhost:8001/img_color_analysis?n_colors=5" \
     -F "file=@test_image.jpg"
```

### 6. `POST /img_caption`

Gera descri√ß√£o autom√°tica da imagem usando modelos de captioning.

**Par√¢metros:**
- `file` (multipart/form-data): Arquivo de imagem
- `max_length` (query, opcional): Comprimento m√°ximo da descri√ß√£o em palavras (padr√£o: 50)

**Resposta:**
```json
{
  "caption": "A woman smiling while holding a cosmetic product",
  "method": "blip",
  "confidence": 0.85,
  "length": 8
}
```

**Exemplo:**
```bash
curl -X POST "http://localhost:8001/img_caption?max_length=50" \
     -F "file=@test_image.jpg"
```

### 7. `POST /img_emotion_detection`

Detecta emo√ß√µes em faces presentes na imagem.

**Par√¢metros:**
- `file` (multipart/form-data): Arquivo de imagem

**Resposta:**
```json
{
  "faces_detected": 1,
  "emotions": [
    {
      "face_id": 1,
      "dominant_emotion": "happy",
      "dominant_confidence": 0.92,
      "bbox": {}
    }
  ],
  "scene_emotion": "happy",
  "average_confidence": 0.88,
  "method": "deepface"
}
```

**Exemplo:**
```bash
curl -X POST "http://localhost:8001/img_emotion_detection" \
     -F "file=@test_image.jpg"
```

### 8. `POST /img_attention_analysis`

Analisa mapa de sali√™ncia e pontos de aten√ß√£o visual na imagem.

**Par√¢metros:**
- `file` (multipart/form-data): Arquivo de imagem
- `n_points` (query, opcional): N√∫mero de pontos de aten√ß√£o (padr√£o: 5, m√°ximo: 20)

**Resposta:**
```json
{
  "attention_score": 0.72,
  "focus_center": {
    "x": 320,
    "y": 240,
    "normalized_x": 0.5,
    "normalized_y": 0.5
  },
  "rule_of_thirds_alignment": "aligned",
  "primary_focus_zone": "aligned-0.33-0.33",
  "attention_points": [...]
}
```

**Exemplo:**
```bash
curl -X POST "http://localhost:8001/img_attention_analysis?n_points=5" \
     -F "file=@test_image.jpg"
```

### 9. `POST /img_cta_detection`

Detecta elementos Call-to-Action (CTAs) na imagem baseado em texto e posi√ß√£o.

**Par√¢metros:**
- `file` (multipart/form-data): Arquivo de imagem

**Resposta:**
```json
{
  "cta_present": true,
  "cta_count": 1,
  "cta_elements": [
    {
      "text": "Compre Agora",
      "keywords": ["compre", "agora"],
      "bbox": {},
      "is_strategic_position": true,
      "relative_size": 2.5,
      "confidence": 0.95
    }
  ],
  "effectiveness_score": 0.75,
  "recommendations": ["CTAs bem posicionados"]
}
```

**Exemplo:**
```bash
curl -X POST "http://localhost:8001/img_cta_detection" \
     -F "file=@test_image.jpg"
```

### 10. `POST /img_neuromarketing_report`

Gera relat√≥rio completo de an√°lise neuromarketing combinando todas as an√°lises dispon√≠veis.

**Par√¢metros:**
- `file` (multipart/form-data): Arquivo de imagem

**Resposta:**
```json
{
  "objects": [...],
  "text": {...},
  "colors": {...},
  "caption": {...},
  "emotions": {...},
  "attention": {...},
  "cta": {...},
  "summary": {
    "total_objects": 3,
    "text_present": true,
    "faces_detected": 1,
    "scene_emotion": "happy",
    "emotional_impact": "positive-high",
    "attention_score": 0.72,
    "cta_present": true,
    "cta_effectiveness": 0.75,
    "color_palette": "warm-energetic",
    "recommendations": [...]
  }
}
```

**Exemplo:**
```bash
curl -X POST "http://localhost:8001/img_neuromarketing_report" \
     -F "file=@test_image.jpg"
```

#### `/analisar_imagem_neuromarketing` - An√°lise Completa de Neuromarketing

Endpoint principal para an√°lise completa de neuromarketing com todos os 20 par√¢metros em portugu√™s:

```bash
curl -X POST "http://localhost:8001/analisar_imagem_neuromarketing" \
     -F "file=@test_image.jpg"
```

Retorna an√°lise completa incluindo:
- Express√£o facial e emo√ß√µes
- Dire√ß√£o do olhar
- Paleta de cores e impacto emocional
- Contraste visual
- Profundidade de campo
- Sensa√ß√£o de movimento
- Simetria visual
- Tipo de plano (close-up, m√©dio, aberto)
- Ilumina√ß√£o e temperatura de cor
- S√≠mbolos sociais
- Proximidade social
- Ponto focal de aten√ß√£o
- Linguagem corporal
- Coer√™ncia narrativa
- Gatilhos de escassez
- Textos e tipografia
- Humor e incongru√™ncia
- Textura sensorial
- Ambiente (natural vs artificial)

## üõ† Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos

- Python 3.10 ou superior
- pip

### Instala√ß√£o Local

1. Clone o reposit√≥rio:
```bash
git clone https://github.com/leandrobosaipo/elroi-vision.git
cd elroi-vision
```

2. **IMPORTANTE**: Instale as depend√™ncias antes de iniciar o servidor:
```bash
pip install -r requirements.txt
```

**Nota sobre depend√™ncias opcionais**: Alguns servi√ßos de neuromarketing requerem bibliotecas adicionais que podem ser instaladas separadamente:

- **OCR**: `easyocr` ou `pytesseract` (requer Tesseract instalado no sistema)
- **Caption**: `transformers` e `torch` (para BLIP)
- **Emo√ß√µes**: `deepface` (requer TensorFlow)
- **Aten√ß√£o**: `opencv-python-headless` e `scipy`
- **Gaze/Pose**: `mediapipe` (para an√°lise de olhar e linguagem corporal)
- **Textura**: `scikit-image` (para an√°lise de textura avan√ßada)
- **Cena**: `torchvision` (para classifica√ß√£o de ambiente)

Se algum servi√ßo n√£o estiver dispon√≠vel, o endpoint retornar√° uma mensagem informativa. Os servi√ßos b√°sicos (detec√ß√£o de objetos e an√°lise de cores) funcionam sem depend√™ncias adicionais.

3. Configure as vari√°veis de ambiente (veja se√ß√£o abaixo)

4. Inicie o servidor:
```bash
uvicorn main:app --host 0.0.0.0 --port 8001 --reload
```

**Troubleshooting**: Se encontrar o erro `ModuleNotFoundError: No module named 'ultralytics'`, execute novamente `pip install -r requirements.txt` para garantir que todas as depend√™ncias est√£o instaladas.

### Instala√ß√£o com Docker

1. Construa e inicie o container:
```bash
docker-compose up
```

O servidor estar√° dispon√≠vel em `http://localhost:8001`

## ‚öôÔ∏è Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes vari√°veis:

```env
# Configura√ß√µes do Modelo YOLO
MODEL_PATH=./models/sample_model/yolov8n.pt

# Configura√ß√µes de Detec√ß√£o
CONFIDENCE_THRESHOLD=0.5
IMAGE_SIZE=640
AUGMENT=false

# Configura√ß√µes do Servidor
HOST=0.0.0.0
PORT=8001
RELOAD=false

# CORS - Use * para permitir todas as origens ou liste separado por v√≠rgula
# Exemplo: http://localhost:3000,https://example.com
CORS_ORIGINS=*

# Logging
LOG_LEVEL=INFO
LOG_FILE=log.log
LOG_ROTATION=1 MB

# Ambiente (development, staging, production)
ENVIRONMENT=production
```

### Descri√ß√£o das Vari√°veis

- **MODEL_PATH**: Caminho para o arquivo do modelo YOLO (.pt)
- **CONFIDENCE_THRESHOLD**: Limiar de confian√ßa para detec√ß√µes (0.0 a 1.0)
- **IMAGE_SIZE**: Tamanho da imagem para processamento (padr√£o: 640)
- **AUGMENT**: Habilita aumento de dados (true/false)
- **HOST**: Endere√ßo IP do servidor
- **PORT**: Porta do servidor
- **RELOAD**: Habilita reload autom√°tico em desenvolvimento (true/false)
- **CORS_ORIGINS**: Origens permitidas para CORS (* para todas)
- **LOG_LEVEL**: N√≠vel de log (DEBUG, INFO, WARNING, ERROR)
- **LOG_FILE**: Arquivo de log
- **LOG_ROTATION**: Tamanho m√°ximo do arquivo de log antes de rotacionar
- **ENVIRONMENT**: Ambiente de execu√ß√£o

## üìö Documenta√ß√£o Swagger

A documenta√ß√£o interativa da API est√° dispon√≠vel em:

- **Swagger UI**: `http://localhost:8001/docs`
- **ReDoc**: `http://localhost:8001/redoc`
- **OpenAPI JSON**: `http://localhost:8001/openapi.json`

A documenta√ß√£o inclui:
- Descri√ß√£o detalhada de cada endpoint
- Exemplos de requisi√ß√µes e respostas
- Schemas de valida√ß√£o
- C√≥digos de erro poss√≠veis
- Interface interativa para testar os endpoints

## üö¢ Deploy no EasyPanel

### Pr√©-requisitos

- Conta no EasyPanel
- Reposit√≥rio Git configurado
- Modelo YOLO dispon√≠vel

### Passo a Passo

1. **Criar Nova Aplica√ß√£o**
   - Acesse o painel do EasyPanel
   - Clique em "New App"
   - Selecione "Git Repository"
   - Conecte seu reposit√≥rio GitHub/GitLab

2. **Configurar Build**
   - **Build Command**: Deixe vazio (usar√° Dockerfile)
   - **Dockerfile**: O projeto j√° inclui um Dockerfile
   - **Build Context**: `/`

3. **Configurar Vari√°veis de Ambiente**
   
   No EasyPanel, v√° em "Environment Variables" e adicione:

   ```
   MODEL_PATH=/app/models/sample_model/yolov8n.pt
   CONFIDENCE_THRESHOLD=0.5
   IMAGE_SIZE=640
   AUGMENT=false
   HOST=0.0.0.0
   PORT=8001
   CORS_ORIGINS=*
   LOG_LEVEL=INFO
   ENVIRONMENT=production
   ```

4. **Configurar Storage/Volumes**
   
   Se o modelo n√£o estiver no reposit√≥rio, configure um volume:
   - **Volume Path**: `/app/models`
   - **Mount Path**: `/app/models`
   - Fa√ßa upload do modelo YOLO para este volume

5. **Configurar Porta**
   - **Port**: `8001`
   - **Protocol**: `HTTP`

6. **Configurar Healthcheck**
   - **Healthcheck Path**: `/healthcheck`
   - **Healthcheck Interval**: `30s`
   - **Healthcheck Timeout**: `10s`

7. **Deploy**
   - Clique em "Deploy"
   - Aguarde o build e deploy completarem
   - Acesse a URL fornecida pelo EasyPanel

### Comandos de Deploy Alternativos

Se preferir usar comandos customizados:

**Start Command:**
```bash
uvicorn main:app --host 0.0.0.0 --port 8001 --workers 4
```

**Ou com Gunicorn:**
```bash
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8001
```

### Verifica√ß√£o P√≥s-Deploy

1. Acesse `https://seu-dominio.com/healthcheck` - deve retornar `{"healthcheck": "Everything OK!"}`
2. Acesse `https://seu-dominio.com/docs` - deve abrir a documenta√ß√£o Swagger
3. Teste um endpoint de detec√ß√£o com uma imagem

## üß™ Testes

Execute os testes com:

```bash
pytest -v --disable-warnings
```

Para executar com cobertura:

```bash
pytest -v --cov=. --cov-report=html
```

## üìÅ Estrutura do Projeto

```
elroi-vision/
‚îú‚îÄ‚îÄ app.py                 # Fun√ß√µes de processamento YOLO
‚îú‚îÄ‚îÄ main.py                # Endpoints FastAPI
‚îú‚îÄ‚îÄ schemas.py             # Schemas Pydantic para valida√ß√£o
‚îú‚îÄ‚îÄ config.py              # Configura√ß√µes e vari√°veis de ambiente
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îú‚îÄ‚îÄ Dockerfile             # Configura√ß√£o Docker
‚îú‚îÄ‚îÄ docker-compose.yaml    # Configura√ß√£o Docker Compose
‚îú‚îÄ‚îÄ models/                # Modelos YOLO
‚îÇ   ‚îî‚îÄ‚îÄ sample_model/
‚îÇ       ‚îî‚îÄ‚îÄ yolov8n.pt
‚îî‚îÄ‚îÄ tests/                 # Testes automatizados
    ‚îú‚îÄ‚îÄ test_app.py
    ‚îî‚îÄ‚îÄ test_main.py
```

## üìù Notas Importantes

- O modelo YOLO precisa estar presente no caminho especificado em `MODEL_PATH`
- Para produ√ß√£o, configure `CORS_ORIGINS` com dom√≠nios espec√≠ficos ao inv√©s de `*`
- O processamento de imagens pode consumir bastante mem√≥ria - ajuste os workers conforme necess√°rio
- Logs s√£o salvos em `log.log` por padr√£o

## üîß Troubleshooting

### Erro ao carregar modelo
- Verifique se o arquivo do modelo existe no caminho especificado
- Confirme que `MODEL_PATH` est√° correto nas vari√°veis de ambiente
- **PyTorch 2.6+**: Se encontrar erro "Weights only load failed", o c√≥digo j√° est√° configurado para lidar com isso automaticamente usando um monkey patch que permite carregar modelos YOLO confi√°veis

### Erro CORS
- Verifique a configura√ß√£o de `CORS_ORIGINS`
- Para desenvolvimento local, use `*`
- Para produ√ß√£o, liste dom√≠nios espec√≠ficos separados por v√≠rgula

### Porta j√° em uso
- Altere a porta nas vari√°veis de ambiente
- Ou pare o processo que est√° usando a porta

### ModuleNotFoundError
- Execute `pip install -r requirements.txt` para instalar todas as depend√™ncias
- Verifique se est√° usando Python 3.10 ou superior
- Certifique-se de que est√° no ambiente virtual correto (se estiver usando um)

## üìÑ Licen√ßa

MIT License

## üë• Contato

Para d√∫vidas ou suporte, abra uma issue no reposit√≥rio.
