{"openapi": "3.0.2", "info": {"title": "ElRoi Vision - Object Detection API", "description": "\n    API de detec\u00e7\u00e3o de objetos usando YOLOv8.\n    \n    ## Funcionalidades\n    \n    * **Detec\u00e7\u00e3o para JSON**: Recebe uma imagem e retorna os objetos detectados em formato JSON\n    * **Detec\u00e7\u00e3o para Imagem**: Recebe uma imagem e retorna a imagem anotada com bounding boxes\n    * **Healthcheck**: Verifica o status do servi\u00e7o\n    * **OCR**: Extra\u00e7\u00e3o de texto de imagens\n    * **An\u00e1lise de Cores**: Identifica cores dominantes e impacto emocional\n    * **Gera\u00e7\u00e3o de Descri\u00e7\u00e3o**: Gera descri\u00e7\u00f5es autom\u00e1ticas de imagens\n    * **An\u00e1lise Emocional**: Detecta emo\u00e7\u00f5es em faces\n    * **An\u00e1lise de Aten\u00e7\u00e3o**: Mapa de sali\u00eancia e pontos de foco\n    * **Detec\u00e7\u00e3o de CTAs**: Identifica elementos Call-to-Action\n    * **Relat\u00f3rio Neuromarketing**: An\u00e1lise completa para an\u00e1lise de marketing\n    \n    ## Modelos\n    \n    O servi\u00e7o utiliza modelos YOLOv8 pr\u00e9-treinados para detec\u00e7\u00e3o de objetos em tempo real,\n    al\u00e9m de modelos especializados para OCR, captioning e an\u00e1lise emocional.\n    ", "contact": {"name": "ElRoi Vision"}, "license": {"name": "MIT"}, "version": "1.0.0"}, "paths": {"/healthcheck": {"get": {"tags": ["Monitoramento"], "summary": "Verificar status do servi\u00e7o", "description": "Endpoint de healthcheck para verificar se o servi\u00e7o est\u00e1 funcionando corretamente.\n    \n    Retorna um status 200 OK se o servi\u00e7o estiver operacional.\n    Este endpoint \u00e9 \u00fatil para:\n    - Monitoramento de sa\u00fade do servi\u00e7o\n    - Load balancers e orquestradores de containers\n    - Verifica\u00e7\u00e3o de disponibilidade antes de fazer requisi\u00e7\u00f5es", "operationId": "perform_healthcheck_healthcheck_get", "responses": {"200": {"description": "Servi\u00e7o est\u00e1 funcionando corretamente", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HealthCheckResponse"}, "example": {"healthcheck": "Everything OK!"}}}}}}}, "/img_object_detection_to_json": {"post": {"tags": ["Detec\u00e7\u00e3o"], "summary": "Detec\u00e7\u00e3o de objetos retornando JSON", "description": "Realiza detec\u00e7\u00e3o de objetos em uma imagem usando YOLOv8 e retorna os resultados em formato JSON.\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem (suporta formatos: JPEG, PNG, WEBP, etc.)\n    \n    ## Resposta\n    \n    Retorna um JSON contendo:\n    - `detect_objects`: Lista de objetos detectados com nome e confian\u00e7a\n    - `detect_objects_names`: String com nomes dos objetos separados por v\u00edrgula\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/img_object_detection_to_json\" \\\n         -H \"accept: application/json\" \\\n         -H \"Content-Type: multipart/form-data\" \\\n         -F \"file=@test_image.jpg\"\n    ```", "operationId": "img_object_detection_to_json_img_object_detection_to_json_post", "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_img_object_detection_to_json_img_object_detection_to_json_post"}}}, "required": true}, "responses": {"200": {"description": "Detec\u00e7\u00e3o realizada com sucesso", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/DetectionResponse"}, "example": {"detect_objects": [{"name": "person", "confidence": 0.95}, {"name": "car", "confidence": 0.87}, {"name": "dog", "confidence": 0.72}], "detect_objects_names": "person, car, dog"}}}}, "400": {"description": "Erro ao processar a imagem", "content": {"application/json": {"example": {"detail": "Invalid image format"}}}}, "422": {"description": "Erro de valida\u00e7\u00e3o - arquivo n\u00e3o fornecido", "content": {"application/json": {"example": {"detail": [{"loc": ["body", "file"], "msg": "field required", "type": "value_error.missing"}]}}}}}}}, "/img_object_detection_to_img": {"post": {"tags": ["Detec\u00e7\u00e3o"], "summary": "Detec\u00e7\u00e3o de objetos retornando imagem anotada", "description": "Realiza detec\u00e7\u00e3o de objetos em uma imagem usando YOLOv8 e retorna a imagem original \n    com bounding boxes e labels desenhados.\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem (suporta formatos: JPEG, PNG, WEBP, etc.)\n    \n    ## Resposta\n    \n    Retorna a imagem processada em formato JPEG com:\n    - Bounding boxes desenhados ao redor dos objetos detectados\n    - Labels com nome da classe e porcentagem de confian\u00e7a\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/img_object_detection_to_img\" \\\n         -H \"accept: image/jpeg\" \\\n         -H \"Content-Type: multipart/form-data\" \\\n         -F \"file=@test_image.jpg\" \\\n         --output result.jpg\n    ```\n    \n    Ou usando Python:\n    ```python\n    import requests\n    \n    with open('test_image.jpg', 'rb') as f:\n        response = requests.post(\n            'http://localhost:8001/img_object_detection_to_img',\n            files={'file': f}\n        )\n    \n    with open('result.jpg', 'wb') as f:\n        f.write(response.content)\n    ```", "operationId": "img_object_detection_to_img_img_object_detection_to_img_post", "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_img_object_detection_to_img_img_object_detection_to_img_post"}}}, "required": true}, "responses": {"200": {"description": "Imagem processada com sucesso", "content": {"application/json": {"schema": {}}, "image/jpeg": {"example": "Imagem JPEG com bounding boxes desenhados"}}}, "400": {"description": "Erro ao processar a imagem", "content": {"application/json": {"example": {"detail": "Invalid image format"}}}}, "422": {"description": "Erro de valida\u00e7\u00e3o - arquivo n\u00e3o fornecido", "content": {"application/json": {"example": {"detail": [{"loc": ["body", "file"], "msg": "field required", "type": "value_error.missing"}]}}}}}}}, "/img_text_extraction": {"post": {"tags": ["Neuromarketing"], "summary": "Extra\u00e7\u00e3o de texto (OCR)", "description": "Extrai texto de uma imagem usando OCR (Optical Character Recognition).\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem (JPEG, PNG, WEBP, etc.)\n    - **method** (opcional): M\u00e9todo de OCR - \"easyocr\" ou \"tesseract\" (padr\u00e3o: \"easyocr\")\n    \n    ## Resposta\n    \n    Retorna texto extra\u00eddo com coordenadas de cada segmento detectado.\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/img_text_extraction\" \\\n         -H \"accept: application/json\" \\\n         -F \"file=@test_image.jpg\" \\\n         -F \"method=easyocr\"\n    ```", "operationId": "img_text_extraction_img_text_extraction_post", "parameters": [{"description": "M\u00e9todo de OCR: 'easyocr' ou 'tesseract'", "required": false, "schema": {"title": "Method", "type": "string", "description": "M\u00e9todo de OCR: 'easyocr' ou 'tesseract'", "default": "easyocr"}, "example": "easyocr", "name": "method", "in": "query"}], "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_img_text_extraction_img_text_extraction_post"}}}, "required": true}, "responses": {"200": {"description": "Texto extra\u00eddo com sucesso", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/OCRResponse"}, "example": {"full_text": "Frete Gr\u00e1tis Compre Agora", "segments": [{"text": "Frete Gr\u00e1tis", "confidence": 0.95, "bbox": {"xmin": 100, "ymin": 50, "xmax": 300, "ymax": 80}}], "total_segments": 1, "method_used": "easyocr"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/img_color_analysis": {"post": {"tags": ["Neuromarketing"], "summary": "An\u00e1lise de cores", "description": "Analisa cores dominantes e impacto emocional de uma imagem.\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem\n    - **n_colors** (opcional): N\u00famero de cores dominantes a extrair (padr\u00e3o: 5)\n    \n    ## Resposta\n    \n    Retorna cores dominantes com porcentagem, tags emocionais e an\u00e1lise de contraste.\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/img_color_analysis\" \\\n         -H \"accept: application/json\" \\\n         -F \"file=@test_image.jpg\" \\\n         -F \"n_colors=5\"\n    ```", "operationId": "img_color_analysis_img_color_analysis_post", "parameters": [{"description": "N\u00famero de cores dominantes a extrair", "required": false, "schema": {"title": "N Colors", "maximum": 10.0, "minimum": 1.0, "type": "integer", "description": "N\u00famero de cores dominantes a extrair", "default": 5}, "example": 5, "name": "n_colors", "in": "query"}], "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_img_color_analysis_img_color_analysis_post"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/ColorAnalysisResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/img_caption": {"post": {"tags": ["Neuromarketing"], "summary": "Gera\u00e7\u00e3o de descri\u00e7\u00e3o", "description": "Gera descri\u00e7\u00e3o autom\u00e1tica da imagem usando modelos de captioning.\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem\n    - **max_length** (opcional): Comprimento m\u00e1ximo da descri\u00e7\u00e3o em palavras (padr\u00e3o: 50)\n    \n    ## Resposta\n    \n    Retorna descri\u00e7\u00e3o textual da imagem.\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/img_caption\" \\\n         -H \"accept: application/json\" \\\n         -F \"file=@test_image.jpg\"\n    ```", "operationId": "img_caption_img_caption_post", "parameters": [{"description": "Comprimento m\u00e1ximo da descri\u00e7\u00e3o em palavras", "required": false, "schema": {"title": "Max Length", "maximum": 100.0, "minimum": 10.0, "type": "integer", "description": "Comprimento m\u00e1ximo da descri\u00e7\u00e3o em palavras", "default": 50}, "example": 50, "name": "max_length", "in": "query"}], "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_img_caption_img_caption_post"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/CaptionResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/img_emotion_detection": {"post": {"tags": ["Neuromarketing"], "summary": "Detec\u00e7\u00e3o de emo\u00e7\u00f5es", "description": "Detecta emo\u00e7\u00f5es em faces presentes na imagem.\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem\n    \n    ## Resposta\n    \n    Retorna emo\u00e7\u00f5es detectadas em cada face e emo\u00e7\u00e3o geral da cena.\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/img_emotion_detection\" \\\n         -H \"accept: application/json\" \\\n         -F \"file=@test_image.jpg\"\n    ```", "operationId": "img_emotion_detection_img_emotion_detection_post", "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_img_emotion_detection_img_emotion_detection_post"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/EmotionResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/img_attention_analysis": {"post": {"tags": ["Neuromarketing"], "summary": "An\u00e1lise de aten\u00e7\u00e3o visual", "description": "Analisa mapa de sali\u00eancia e pontos de aten\u00e7\u00e3o visual na imagem.\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem\n    - **n_points** (opcional): N\u00famero de pontos de aten\u00e7\u00e3o a retornar (padr\u00e3o: 5)\n    \n    ## Resposta\n    \n    Retorna mapa de aten\u00e7\u00e3o, centro de foco e alinhamento com regra dos ter\u00e7os.\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/img_attention_analysis\" \\\n         -H \"accept: application/json\" \\\n         -F \"file=@test_image.jpg\"\n    ```", "operationId": "img_attention_analysis_img_attention_analysis_post", "parameters": [{"description": "N\u00famero de pontos de aten\u00e7\u00e3o a retornar", "required": false, "schema": {"title": "N Points", "maximum": 20.0, "minimum": 1.0, "type": "integer", "description": "N\u00famero de pontos de aten\u00e7\u00e3o a retornar", "default": 5}, "example": 5, "name": "n_points", "in": "query"}], "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_img_attention_analysis_img_attention_analysis_post"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/SaliencyResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/img_cta_detection": {"post": {"tags": ["Neuromarketing"], "summary": "Detec\u00e7\u00e3o de CTAs", "description": "Detecta elementos Call-to-Action (CTAs) na imagem baseado em texto e posi\u00e7\u00e3o.\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem\n    \n    ## Resposta\n    \n    Retorna CTAs detectados com an\u00e1lise de efetividade.\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/img_cta_detection\" \\\n         -H \"accept: application/json\" \\\n         -F \"file=@test_image.jpg\"\n    ```", "operationId": "img_cta_detection_img_cta_detection_post", "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_img_cta_detection_img_cta_detection_post"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/CTAResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/img_neuromarketing_report": {"post": {"tags": ["Neuromarketing"], "summary": "Relat\u00f3rio completo de neuromarketing", "description": "Gera relat\u00f3rio completo de an\u00e1lise neuromarketing combinando todas as an\u00e1lises dispon\u00edveis.\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem\n    \n    ## Resposta\n    \n    Retorna relat\u00f3rio completo com:\n    - Objetos detectados\n    - Texto extra\u00eddo (OCR)\n    - An\u00e1lise de cores\n    - Descri\u00e7\u00e3o gerada\n    - An\u00e1lise emocional\n    - An\u00e1lise de aten\u00e7\u00e3o\n    - Detec\u00e7\u00e3o de CTAs\n    - Resumo executivo\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/img_neuromarketing_report\" \\\n         -H \"accept: application/json\" \\\n         -F \"file=@test_image.jpg\"\n    ```", "operationId": "img_neuromarketing_report_img_neuromarketing_report_post", "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_img_neuromarketing_report_img_neuromarketing_report_post"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/NeuromarketingReportResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}, "/analisar_imagem_neuromarketing": {"post": {"tags": ["Neuromarketing"], "summary": "An\u00e1lise completa de neuromarketing", "description": "Analisa imagem completa com base em princ\u00edpios de neuromarketing.\n    \n    Identifica elementos visuais e emocionais que influenciam o comportamento humano:\n    \n    - **Express\u00e3o facial**: Emo\u00e7\u00f5es detectadas e impacto emocional\n    - **Dire\u00e7\u00e3o do olhar**: Para onde o olhar est\u00e1 direcionado\n    - **Paleta de cores**: Cores dominantes e impacto emocional\n    - **Contraste visual**: An\u00e1lise de contraste e hierarquia visual\n    - **Profundidade de campo**: An\u00e1lise de foco e blur\n    - **Movimento impl\u00edcito**: Sensa\u00e7\u00e3o de movimento e a\u00e7\u00e3o\n    - **Simetria visual**: Equil\u00edbrio e harmonia visual\n    - **Tipo de plano**: Close-up, m\u00e9dio ou aberto\n    - **Ilumina\u00e7\u00e3o**: Temperatura de cor e impacto emocional\n    - **S\u00edmbolos sociais**: Objetos que despertam pertencimento\n    - **Proximidade social**: N\u00famero de pessoas e contexto\n    - **Ponto focal**: \u00c1rea de maior aten\u00e7\u00e3o visual\n    - **Linguagem corporal**: Postura e comunica\u00e7\u00e3o n\u00e3o-verbal\n    - **Coer\u00eancia narrativa**: Hist\u00f3ria impl\u00edcita na imagem\n    - **Gatilhos de escassez**: Elementos de urg\u00eancia detectados\n    - **Textos**: An\u00e1lise de textos e tipografia\n    - **Humor/incongru\u00eancia**: Efeitos de surpresa detectados\n    - **Textura**: Sensa\u00e7\u00f5es t\u00e1teis evocadas\n    - **Ambiente**: Classifica\u00e7\u00e3o natural vs artificial\n    \n    ## Par\u00e2metros\n    \n    - **file**: Arquivo de imagem\n    \n    ## Resposta\n    \n    Retorna an\u00e1lise completa com todos os par\u00e2metros em portugu\u00eas e explica\u00e7\u00f5es baseadas em neuromarketing.\n    \n    ## Exemplo de Uso\n    \n    ```bash\n    curl -X POST \"http://localhost:8001/analisar_imagem_neuromarketing\" \\\n         -H \"accept: application/json\" \\\n         -F \"file=@test_image.jpg\"\n    ```", "operationId": "analisar_imagem_neuromarketing_analisar_imagem_neuromarketing_post", "requestBody": {"content": {"multipart/form-data": {"schema": {"$ref": "#/components/schemas/Body_analisar_imagem_neuromarketing_analisar_imagem_neuromarketing_post"}}}, "required": true}, "responses": {"200": {"description": "Successful Response", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/NeuromarketingDetailedResponse"}}}}, "422": {"description": "Validation Error", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}}}}}}, "components": {"schemas": {"AttentionPoint": {"title": "AttentionPoint", "required": ["x", "y", "score", "normalized_x", "normalized_y"], "type": "object", "properties": {"x": {"title": "X", "type": "integer", "description": "Coordenada X", "example": 320}, "y": {"title": "Y", "type": "integer", "description": "Coordenada Y", "example": 240}, "score": {"title": "Score", "type": "number", "description": "Score de aten\u00e7\u00e3o", "example": 0.85}, "normalized_x": {"title": "Normalized X", "type": "number", "description": "X normalizado (0-1)", "example": 0.5}, "normalized_y": {"title": "Normalized Y", "type": "number", "description": "Y normalizado (0-1)", "example": 0.5}}, "description": "Ponto de aten\u00e7\u00e3o visual"}, "Body_analisar_imagem_neuromarketing_analisar_imagem_neuromarketing_post": {"title": "Body_analisar_imagem_neuromarketing_analisar_imagem_neuromarketing_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para an\u00e1lise completa de neuromarketing", "format": "binary"}}}, "Body_img_attention_analysis_img_attention_analysis_post": {"title": "Body_img_attention_analysis_img_attention_analysis_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para an\u00e1lise de aten\u00e7\u00e3o", "format": "binary"}}}, "Body_img_caption_img_caption_post": {"title": "Body_img_caption_img_caption_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para gera\u00e7\u00e3o de descri\u00e7\u00e3o", "format": "binary"}}}, "Body_img_color_analysis_img_color_analysis_post": {"title": "Body_img_color_analysis_img_color_analysis_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para an\u00e1lise de cores", "format": "binary"}}}, "Body_img_cta_detection_img_cta_detection_post": {"title": "Body_img_cta_detection_img_cta_detection_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para detec\u00e7\u00e3o de CTAs", "format": "binary"}}}, "Body_img_emotion_detection_img_emotion_detection_post": {"title": "Body_img_emotion_detection_img_emotion_detection_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para detec\u00e7\u00e3o de emo\u00e7\u00f5es", "format": "binary"}}}, "Body_img_neuromarketing_report_img_neuromarketing_report_post": {"title": "Body_img_neuromarketing_report_img_neuromarketing_report_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para an\u00e1lise completa", "format": "binary"}}}, "Body_img_object_detection_to_img_img_object_detection_to_img_post": {"title": "Body_img_object_detection_to_img_img_object_detection_to_img_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para detec\u00e7\u00e3o de objetos", "format": "binary"}}}, "Body_img_object_detection_to_json_img_object_detection_to_json_post": {"title": "Body_img_object_detection_to_json_img_object_detection_to_json_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para detec\u00e7\u00e3o de objetos", "format": "binary"}}}, "Body_img_text_extraction_img_text_extraction_post": {"title": "Body_img_text_extraction_img_text_extraction_post", "required": ["file"], "type": "object", "properties": {"file": {"title": "File", "type": "string", "description": "Arquivo de imagem para extra\u00e7\u00e3o de texto", "format": "binary"}}}, "CTAElement": {"title": "CTAElement", "required": ["text", "keywords", "bbox", "is_strategic_position", "relative_size", "confidence"], "type": "object", "properties": {"text": {"title": "Text", "type": "string", "description": "Texto do CTA", "example": "Compre Agora"}, "keywords": {"title": "Keywords", "type": "array", "items": {"type": "string"}, "description": "Palavras-chave detectadas", "example": ["compre", "agora"]}, "bbox": {"title": "Bbox", "type": "object", "additionalProperties": {"type": "number"}, "description": "Coordenadas do CTA"}, "is_strategic_position": {"title": "Is Strategic Position", "type": "boolean", "description": "Se est\u00e1 em posi\u00e7\u00e3o estrat\u00e9gica", "example": true}, "relative_size": {"title": "Relative Size", "type": "number", "description": "Tamanho relativo (%)", "example": 2.5}, "confidence": {"title": "Confidence", "type": "number", "description": "Confian\u00e7a", "example": 0.95}}, "description": "Elemento Call-to-Action detectado"}, "CTAResponse": {"title": "CTAResponse", "required": ["cta_present", "cta_count", "cta_elements", "effectiveness_score", "recommendations"], "type": "object", "properties": {"cta_present": {"title": "Cta Present", "type": "boolean", "description": "Se h\u00e1 CTA presente", "example": true}, "cta_count": {"title": "Cta Count", "type": "integer", "description": "N\u00famero de CTAs", "example": 1}, "cta_elements": {"title": "Cta Elements", "type": "array", "items": {"$ref": "#/components/schemas/CTAElement"}, "description": "Elementos CTA detectados"}, "effectiveness_score": {"title": "Effectiveness Score", "type": "number", "description": "Score de efetividade", "example": 0.75}, "recommendations": {"title": "Recommendations", "type": "array", "items": {"type": "string"}, "description": "Recomenda\u00e7\u00f5es", "example": ["CTAs bem posicionados"]}}, "description": "Resposta da detec\u00e7\u00e3o de CTAs"}, "CaptionResponse": {"title": "CaptionResponse", "required": ["caption", "method", "confidence"], "type": "object", "properties": {"caption": {"title": "Caption", "type": "string", "description": "Descri\u00e7\u00e3o gerada", "example": "A woman smiling while holding a cosmetic product"}, "method": {"title": "Method", "type": "string", "description": "M\u00e9todo usado", "example": "blip"}, "confidence": {"title": "Confidence", "type": "number", "description": "Confian\u00e7a da descri\u00e7\u00e3o", "example": 0.85}, "length": {"title": "Length", "type": "integer", "description": "N\u00famero de palavras", "example": 8}}, "description": "Resposta da gera\u00e7\u00e3o de descri\u00e7\u00e3o"}, "ColorAnalysisResponse": {"title": "ColorAnalysisResponse", "required": ["dominant_colors", "average_contrast", "emotion_palette", "color_count"], "type": "object", "properties": {"dominant_colors": {"title": "Dominant Colors", "type": "array", "items": {"$ref": "#/components/schemas/DominantColor"}, "description": "Cores dominantes"}, "average_contrast": {"title": "Average Contrast", "type": "number", "description": "Contraste m\u00e9dio", "example": 4.8}, "emotion_palette": {"title": "Emotion Palette", "type": "string", "description": "Paleta emocional geral", "example": "warm-energetic"}, "color_count": {"title": "Color Count", "type": "integer", "description": "N\u00famero de cores analisadas", "example": 5}}, "description": "Resposta da an\u00e1lise de cores"}, "DetectionObject": {"title": "DetectionObject", "required": ["name", "confidence"], "type": "object", "properties": {"name": {"title": "Name", "type": "string", "description": "Nome da classe do objeto detectado", "example": "person"}, "confidence": {"title": "Confidence", "maximum": 1.0, "minimum": 0.0, "type": "number", "description": "Confian\u00e7a da detec\u00e7\u00e3o (0.0 a 1.0)", "example": 0.95}}, "description": "Objeto detectado na imagem"}, "DetectionResponse": {"title": "DetectionResponse", "required": ["detect_objects", "detect_objects_names"], "type": "object", "properties": {"detect_objects": {"title": "Detect Objects", "type": "array", "items": {"$ref": "#/components/schemas/DetectionObject"}, "description": "Lista de objetos detectados"}, "detect_objects_names": {"title": "Detect Objects Names", "type": "string", "description": "Nomes dos objetos detectados separados por v\u00edrgula", "example": "person, car, dog"}}, "description": "Resposta da detec\u00e7\u00e3o de objetos em formato JSON"}, "DominantColor": {"title": "DominantColor", "required": ["rgb", "hex", "percentage", "emotion_tag"], "type": "object", "properties": {"rgb": {"title": "Rgb", "type": "array", "items": {"type": "integer"}, "description": "Valores RGB", "example": [255, 100, 50]}, "hex": {"title": "Hex", "type": "string", "description": "Cor em hexadecimal", "example": "#FF6432"}, "percentage": {"title": "Percentage", "type": "number", "description": "Porcentagem da cor na imagem", "example": 35.5}, "emotion_tag": {"title": "Emotion Tag", "type": "string", "description": "Tag emocional da cor", "example": "warm-energetic"}}, "description": "Cor dominante detectada"}, "EmotionResponse": {"title": "EmotionResponse", "required": ["faces_detected", "emotions", "scene_emotion", "average_confidence", "method"], "type": "object", "properties": {"faces_detected": {"title": "Faces Detected", "type": "integer", "description": "N\u00famero de faces detectadas", "example": 1}, "emotions": {"title": "Emotions", "type": "array", "items": {"$ref": "#/components/schemas/FaceEmotion"}, "description": "Emo\u00e7\u00f5es detectadas"}, "scene_emotion": {"title": "Scene Emotion", "type": "string", "description": "Emo\u00e7\u00e3o geral da cena", "example": "happy"}, "average_confidence": {"title": "Average Confidence", "type": "number", "description": "Confian\u00e7a m\u00e9dia", "example": 0.88}, "method": {"title": "Method", "type": "string", "description": "M\u00e9todo usado", "example": "deepface"}}, "description": "Resposta da detec\u00e7\u00e3o de emo\u00e7\u00f5es"}, "FaceEmotion": {"title": "FaceEmotion", "required": ["face_id", "dominant_emotion", "dominant_confidence", "bbox"], "type": "object", "properties": {"face_id": {"title": "Face Id", "type": "integer", "description": "ID da face", "example": 1}, "dominant_emotion": {"title": "Dominant Emotion", "type": "string", "description": "Emo\u00e7\u00e3o dominante", "example": "happy"}, "dominant_confidence": {"title": "Dominant Confidence", "type": "number", "description": "Confian\u00e7a da emo\u00e7\u00e3o", "example": 0.92}, "bbox": {"title": "Bbox", "type": "object", "description": "Coordenadas da face"}}, "description": "Emo\u00e7\u00e3o detectada em uma face"}, "HTTPValidationError": {"title": "HTTPValidationError", "type": "object", "properties": {"detail": {"title": "Detail", "type": "array", "items": {"$ref": "#/components/schemas/ValidationError"}}}}, "HealthCheckResponse": {"title": "HealthCheckResponse", "required": ["healthcheck"], "type": "object", "properties": {"healthcheck": {"title": "Healthcheck", "type": "string", "description": "Status do servi\u00e7o", "example": "Everything OK!"}}, "description": "Resposta do healthcheck"}, "NeuromarketingDetailedResponse": {"title": "NeuromarketingDetailedResponse", "required": ["expressao_emocional", "direcao_olhar", "cores_dominantes", "emocao_das_cores", "contraste_local", "profundidade_de_campo", "sensacao_de_movimento", "simetria_visual", "tipo_de_plano", "iluminacao_emocional", "simbolos_sociais", "numero_de_pessoas", "objetos", "area_de_atencao_visual", "postura_corporea", "historia_implicita", "gatilho_escassez_visual", "texto_em_imagem", "textos_e_tipografia", "efeito_surpresa_ou_ironia", "textura_sensorial", "natureza_vs_tecnologia"], "type": "object", "properties": {"expressao_emocional": {"title": "Expressao Emocional", "type": "object", "description": "An\u00e1lise de express\u00f5es faciais e emo\u00e7\u00f5es detectadas"}, "direcao_olhar": {"title": "Direcao Olhar", "type": "object", "description": "Dire\u00e7\u00e3o do olhar e regi\u00e3o focada"}, "cores_dominantes": {"title": "Cores Dominantes", "type": "object", "description": "Cores dominantes e an\u00e1lise emocional"}, "emocao_das_cores": {"title": "Emocao Das Cores", "type": "object", "description": "Impacto emocional das cores"}, "contraste_local": {"title": "Contraste Local", "type": "object", "description": "An\u00e1lise de contraste visual"}, "profundidade_de_campo": {"title": "Profundidade De Campo", "type": "object", "description": "An\u00e1lise de profundidade de campo e foco"}, "sensacao_de_movimento": {"title": "Sensacao De Movimento", "type": "object", "description": "Sensa\u00e7\u00e3o de movimento detectada"}, "simetria_visual": {"title": "Simetria Visual", "type": "object", "description": "An\u00e1lise de simetria visual"}, "tipo_de_plano": {"title": "Tipo De Plano", "type": "object", "description": "Tipo de plano (close-up, m\u00e9dio, aberto)"}, "iluminacao_emocional": {"title": "Iluminacao Emocional", "type": "object", "description": "An\u00e1lise de ilumina\u00e7\u00e3o e temperatura de cor"}, "simbolos_sociais": {"title": "Simbolos Sociais", "type": "object", "description": "S\u00edmbolos sociais detectados"}, "numero_de_pessoas": {"title": "Numero De Pessoas", "type": "integer", "description": "N\u00famero de pessoas detectadas na imagem"}, "objetos": {"title": "Objetos", "type": "array", "items": {"type": "object"}, "description": "Lista de objetos detectados"}, "area_de_atencao_visual": {"title": "Area De Atencao Visual", "type": "object", "description": "Mapa de aten\u00e7\u00e3o visual e pontos focais"}, "postura_corporea": {"title": "Postura Corporea", "type": "object", "description": "An\u00e1lise de linguagem corporal e postura"}, "historia_implicita": {"title": "Historia Implicita", "type": "object", "description": "Narrativa impl\u00edcita e coer\u00eancia contextual"}, "gatilho_escassez_visual": {"title": "Gatilho Escassez Visual", "type": "object", "description": "Elementos de urg\u00eancia e escassez detectados"}, "texto_em_imagem": {"title": "Texto Em Imagem", "type": "object", "description": "Texto extra\u00eddo da imagem"}, "textos_e_tipografia": {"title": "Textos E Tipografia", "type": "object", "description": "An\u00e1lise de textos e tipografia"}, "efeito_surpresa_ou_ironia": {"title": "Efeito Surpresa Ou Ironia", "type": "object", "description": "Detec\u00e7\u00e3o de humor e incongru\u00eancia"}, "textura_sensorial": {"title": "Textura Sensorial", "type": "object", "description": "An\u00e1lise de textura e sensa\u00e7\u00f5es t\u00e1teis"}, "natureza_vs_tecnologia": {"title": "Natureza Vs Tecnologia", "type": "object", "description": "Classifica\u00e7\u00e3o de ambiente (natural vs artificial)"}}, "description": "Resposta completa de an\u00e1lise neuromarketing com todos os par\u00e2metros em portugu\u00eas"}, "NeuromarketingReportResponse": {"title": "NeuromarketingReportResponse", "required": ["objects", "text", "colors", "caption", "emotions", "attention", "cta", "summary"], "type": "object", "properties": {"objects": {"title": "Objects", "type": "array", "items": {"$ref": "#/components/schemas/DetectionObject"}, "description": "Objetos detectados"}, "text": {"title": "Text", "allOf": [{"$ref": "#/components/schemas/OCRResponse"}], "description": "An\u00e1lise de texto"}, "colors": {"title": "Colors", "allOf": [{"$ref": "#/components/schemas/ColorAnalysisResponse"}], "description": "An\u00e1lise de cores"}, "caption": {"title": "Caption", "allOf": [{"$ref": "#/components/schemas/CaptionResponse"}], "description": "Descri\u00e7\u00e3o da imagem"}, "emotions": {"title": "Emotions", "allOf": [{"$ref": "#/components/schemas/EmotionResponse"}], "description": "An\u00e1lise emocional"}, "attention": {"title": "Attention", "allOf": [{"$ref": "#/components/schemas/SaliencyResponse"}], "description": "An\u00e1lise de aten\u00e7\u00e3o"}, "cta": {"title": "Cta", "allOf": [{"$ref": "#/components/schemas/CTAResponse"}], "description": "An\u00e1lise de CTAs"}, "summary": {"title": "Summary", "type": "object", "description": "Resumo executivo"}}, "description": "Resposta completa do relat\u00f3rio de neuromarketing"}, "OCRResponse": {"title": "OCRResponse", "required": ["full_text", "segments", "total_segments", "method_used"], "type": "object", "properties": {"full_text": {"title": "Full Text", "type": "string", "description": "Texto completo extra\u00eddo", "example": "Frete Gr\u00e1tis Compre Agora"}, "segments": {"title": "Segments", "type": "array", "items": {"$ref": "#/components/schemas/TextSegment"}, "description": "Segmentos de texto com coordenadas"}, "total_segments": {"title": "Total Segments", "type": "integer", "description": "N\u00famero total de segmentos", "example": 2}, "method_used": {"title": "Method Used", "type": "string", "description": "M\u00e9todo usado para OCR", "example": "easyocr"}}, "description": "Resposta da extra\u00e7\u00e3o de texto (OCR)"}, "SaliencyResponse": {"title": "SaliencyResponse", "required": ["attention_score", "focus_center", "rule_of_thirds_alignment", "primary_focus_zone"], "type": "object", "properties": {"attention_score": {"title": "Attention Score", "type": "number", "description": "Score geral de aten\u00e7\u00e3o", "example": 0.72}, "focus_center": {"title": "Focus Center", "type": "object", "additionalProperties": {"type": "number"}, "description": "Centro de foco", "example": {"x": 320, "y": 240, "normalized_x": 0.5, "normalized_y": 0.5}}, "rule_of_thirds_alignment": {"title": "Rule Of Thirds Alignment", "type": "string", "description": "Alinhamento com regra dos ter\u00e7os", "example": "aligned"}, "primary_focus_zone": {"title": "Primary Focus Zone", "type": "string", "description": "Zona de foco prim\u00e1rio", "example": "aligned-0.33-0.33"}, "attention_points": {"title": "Attention Points", "type": "array", "items": {"$ref": "#/components/schemas/AttentionPoint"}, "description": "Pontos de maior aten\u00e7\u00e3o", "default": []}}, "description": "Resposta da an\u00e1lise de sali\u00eancia"}, "TextSegment": {"title": "TextSegment", "required": ["text", "confidence", "bbox"], "type": "object", "properties": {"text": {"title": "Text", "type": "string", "description": "Texto extra\u00eddo", "example": "Frete Gr\u00e1tis"}, "confidence": {"title": "Confidence", "maximum": 1.0, "minimum": 0.0, "type": "number", "description": "Confian\u00e7a da detec\u00e7\u00e3o", "example": 0.92}, "bbox": {"title": "Bbox", "type": "object", "additionalProperties": {"type": "number"}, "description": "Coordenadas do bounding box", "example": {"xmin": 100, "ymin": 50, "xmax": 300, "ymax": 80}}}, "description": "Segmento de texto detectado"}, "ValidationError": {"title": "ValidationError", "required": ["loc", "msg", "type"], "type": "object", "properties": {"loc": {"title": "Location", "type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}}, "msg": {"title": "Message", "type": "string"}, "type": {"title": "Error Type", "type": "string"}}}}}}